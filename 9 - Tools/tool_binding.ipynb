{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6fbed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4eecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871b7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model_name=\"llama-3.1-8b-instant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544dbd9",
   "metadata": {},
   "source": [
    "# create tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a437acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a:int,b:int)-> int:\n",
    "    \"\"\"mulitpy of two number\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52af43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530\n"
     ]
    }
   ],
   "source": [
    "print(multiply.invoke({'a': 34, 'b': 45}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d3e0e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbee557",
   "metadata": {},
   "source": [
    "# tool binding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a68b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002A61D133880>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002A61D179CF0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'mulitpy of two number', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool binding\n",
    "\n",
    "llm_with_tool =llm.bind_tools([multiply])\n",
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf6dbb",
   "metadata": {},
   "source": [
    "## tool_colling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42cb3df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 221, 'total_tokens': 244, 'completion_time': 0.024218077, 'prompt_time': 0.012142888, 'queue_time': 0.050923262, 'total_time': 0.036360965}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a06bee59-a761-423b-931f-51eca2647702-0', usage_metadata={'input_tokens': 221, 'output_tokens': 23, 'total_tokens': 244})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(\"who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2886fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meatain the message history or chat history\n",
    "from langchain_core.messages import HumanMessage\n",
    "queary = HumanMessage(\"can you solve the question 2 mulitiply by 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af47a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messagees = [queary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83833416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='can you solve the question 2 mulitiply by 6', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messagees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d0dfc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reslut = llm_with_tool.invoke(messagees) # content is empty after the AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdaef85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messagees.append(reslut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24a19bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='can you solve the question 2 mulitiply by 6', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9pnmz3f65', 'function': {'arguments': '{\"a\":2,\"b\":6}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 232, 'total_tokens': 251, 'completion_time': 0.028137107, 'prompt_time': 0.01261989, 'queue_time': 0.050706099, 'total_time': 0.040756997}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e32974efee', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--16816f4b-d4a2-4abd-92ee-4fa6523235d0-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 6}, 'id': '9pnmz3f65', 'type': 'tool_call'}], usage_metadata={'input_tokens': 232, 'output_tokens': 19, 'total_tokens': 251})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messagees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b2bbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 4},\n",
       "  'id': 'fwqvynwb3',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(\"2 mulitiply by 4\").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6f63b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(\"2 mulitiply by 4\").tool_calls[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a9e253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply',\n",
       " 'args': {'a': 2, 'b': 4},\n",
       " 'id': 'cqvbg4we2',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(\"2 mulitiply by 4\").tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b40f01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(\"2 mulitiply by 4\").tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52cda22",
   "metadata": {},
   "source": [
    "## tool Exicution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ee4131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'pvnb8v4da', 'function': {'arguments': '{\"a\":2,\"b\":4}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 226, 'total_tokens': 245, 'completion_time': 0.03264222, 'prompt_time': 0.018719036, 'queue_time': 0.053080144, 'total_time': 0.051361256}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--f53d2bdf-8ccf-415b-99a4-0f1e5e2f0afd-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 4}, 'id': 'pvnb8v4da', 'type': 'tool_call'}] usage_metadata={'input_tokens': 226, 'output_tokens': 19, 'total_tokens': 245}\n"
     ]
    }
   ],
   "source": [
    "result = llm_with_tool.invoke(\"2 mulitiply by 4\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc94cf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke(llm_with_tool.invoke(\"2 mulitiply by 4\").tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c78495be",
   "metadata": {},
   "outputs": [],
   "source": [
    "res= multiply.invoke({'name': 'multiply',\n",
    " 'args': {'a': 2, 'b': 4},\n",
    " 'id': 'jh4pvxbx7',\n",
    " 'type': 'tool_call'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b2cb424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='8', name='multiply', tool_call_id='jh4pvxbx7')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3301dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messagees.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4835eab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='can you solve the question 2 mulitiply by 6', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9pnmz3f65', 'function': {'arguments': '{\"a\":2,\"b\":6}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 232, 'total_tokens': 251, 'completion_time': 0.028137107, 'prompt_time': 0.01261989, 'queue_time': 0.050706099, 'total_time': 0.040756997}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e32974efee', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--16816f4b-d4a2-4abd-92ee-4fa6523235d0-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 6}, 'id': '9pnmz3f65', 'type': 'tool_call'}], usage_metadata={'input_tokens': 232, 'output_tokens': 19, 'total_tokens': 251}),\n",
       " ToolMessage(content='8', name='multiply', tool_call_id='jh4pvxbx7')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messagees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f27b84dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of 2 multiplied by 6 is 12.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 262, 'total_tokens': 276, 'completion_time': 0.018924916, 'prompt_time': 0.014402881, 'queue_time': 0.049700399, 'total_time': 0.033327797}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0e5ecdaa-e943-4736-b919-451de1fb5fe8-0', usage_metadata={'input_tokens': 262, 'output_tokens': 14, 'total_tokens': 276})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(messagees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f502bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
