{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90f2cfa",
   "metadata": {},
   "source": [
    "## Search Engine With Tools And Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv -- Research\n",
    "## tools creation\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcff6d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## used the inbuilt tool of wikipedia\n",
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=100)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "011542f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## used the inbuilt tool of arxiv\n",
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=100)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0664abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2f1458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "### custom tools create [RAG TOOL]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d913dc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3712360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\LC-basics[1]\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")\n",
    "# creat a Embeddign by huggingface\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ddeb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\LC-basics[1]\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000022B01C16E30>, search_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/integrations/tools/\")\n",
    "docs=loader.load()\n",
    "document = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectorDB=FAISS.from_documents(documents=document,embedding=embedding)\n",
    "retriever =vectorDB.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603d6e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langchain-tools'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langchain-tools\", \"search any information about langchain tools\")\n",
    "\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ce52e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'e:\\\\LC-basics[1]\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=100)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=100)),\n",
       " Tool(name='langchain-tools', description='search any information about langchain tools', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000022B02C969E0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000022B01C16E30>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000022B02C96DD0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000022B01C16E30>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [wiki,arxiv,retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run all this tools with Agents and LLM Models\n",
    "\n",
    "## Tools , LLM ----> AgentExecutor\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model_name=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a0d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "## crate prompts template\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb819cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04eb5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000022B39318430>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000022B39318430>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000022B02E165F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000022B02E58AC0>, model_name='llama3-70b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langchain-tools', 'description': 'search any information about langchain tools', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce017b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000022B39318430>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000022B39318430>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000022B02E165F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000022B02E58AC0>, model_name='llama3-70b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langchain-tools', 'description': 'search any information about langchain tools', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'e:\\\\LC-basics[1]\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=100)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=100)), Tool(name='langchain-tools', description='search any information about langchain tools', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000022B02C969E0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000022B01C16E30>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000022B02C96DD0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000022B01C16E30>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Excuter\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_exicuter = AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_exicuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ef8f8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'vice president of india 2025'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Vice President of India\n",
      "Summary: The Vice President of India (ISO: Bhārata kē Uparāṣṭrapati) i\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'list of vice presidents of india'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: List of vice presidents of India\n",
      "Summary: The vice president of India is the second highest co\u001b[0m\u001b[32;1m\u001b[1;3mThe current vice president of India is Jagdeep Dhankhar, who took office on August 11, 2022. However, since you asked about the vice president in 2025, I couldn't find any information on who will be the vice president in 2025 as it's a future event.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'New vice president of india in 2025',\n",
       " 'output': \"The current vice president of India is Jagdeep Dhankhar, who took office on August 11, 2022. However, since you asked about the vice president in 2025, I couldn't find any information on who will be the vice president in 2025 as it's a future event.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exicuter.invoke({\"input\":\"New vice president of india in 2025\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "529a2f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence\u001b[0m\u001b[32;1m\u001b[1;3mMachine learning (ML) is a field of study in artificial intelligence that involves developing algorithms and statistical models that enable machines to learn from data, make decisions, and improve their performance on a given task over time.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is machine learning',\n",
       " 'output': 'Machine learning (ML) is a field of study in artificial intelligence that involves developing algorithms and statistical models that enable machines to learn from data, make decisions, and improve their performance on a given task over time.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exicuter.invoke({\"input\":\"What is machine learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db004e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Prime Minister of India'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Prime Minister of India\n",
      "Summary: The prime minister of India (ISO: Bhārata kē Pradhānamantrī) \u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'List of Prime Ministers of India'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: List of prime ministers of India\n",
      "Summary: The prime minister of India is the chief executive o\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like you're looking for a list of prime ministers of India. Here is the list:\n",
      "\n",
      "1. Jawaharlal Nehru (1947-1964)\n",
      "2. Lal Bahadur Shastri (1964-1966)\n",
      "3. Indira Gandhi (1966-1977)\n",
      "4. Morarji Desai (1977-1979)\n",
      "5. Charan Singh (1979-1980)\n",
      "6. Indira Gandhi (1980-1984)\n",
      "7. Rajiv Gandhi (1984-1989)\n",
      "8. V. P. Singh (1989-1990)\n",
      "9. Chandra Shekhar (1990-1991)\n",
      "10. P. V. Narasimha Rao (1991-1996)\n",
      "11. H. D. Deve Gowda (1996-1997)\n",
      "12. I. K. Gujral (1997-1998)\n",
      "13. Atal Bihari Vajpayee (1998-2004)\n",
      "14. Manmohan Singh (2004-2014)\n",
      "15. Narendra Damodardas Modi (2014-present)\n",
      "\n",
      "Let me know if you need anything else!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'give me a link can i search online (ISO: Bhārata kē Pradhānamantrī)',\n",
       " 'output': \"It seems like you're looking for a list of prime ministers of India. Here is the list:\\n\\n1. Jawaharlal Nehru (1947-1964)\\n2. Lal Bahadur Shastri (1964-1966)\\n3. Indira Gandhi (1966-1977)\\n4. Morarji Desai (1977-1979)\\n5. Charan Singh (1979-1980)\\n6. Indira Gandhi (1980-1984)\\n7. Rajiv Gandhi (1984-1989)\\n8. V. P. Singh (1989-1990)\\n9. Chandra Shekhar (1990-1991)\\n10. P. V. Narasimha Rao (1991-1996)\\n11. H. D. Deve Gowda (1996-1997)\\n12. I. K. Gujral (1997-1998)\\n13. Atal Bihari Vajpayee (1998-2004)\\n14. Manmohan Singh (2004-2014)\\n15. Narendra Damodardas Modi (2014-present)\\n\\nLet me know if you need anything else!\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exicuter.invoke({\"input\":\"give me a link can i search online (ISO: Bhārata kē Pradhānamantrī)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3862007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langchain-tools` with `{'query': 'learn gen ai in details'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\LC-basics[1]\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mWebhooks.InfobipThis notebook that shows how to use Infobip API wrapper to send SMS m...Ionic Shopping ToolIonic is a plug and play ecommerce marketplace for AI Assistants. By ...JenkinsTools for interacting with Jenkins.Jina SearchThis notebook provides a quick overview for getting started with Jina...Jira ToolkitThis notebook goes over how to use the Jira toolkit.JSON ToolkitThis notebook showcases an agent interacting with large JSON/dict obj...Lemon AgentLemon Agent helps you build powerful AI assistants in minutes and aut...LinkupSearchToolLinkup provides an API to connect LLMs to the web and the Linkup Prem...MemgraphThis will help you get started with the Memgraph toolkit.MemorizeFine-tuning LLM itself to memorize information using unsupervised lea...Mojeek SearchThe following notebook will explain how to get results using Mojeek S...MultiOn ToolkitMultiON has built an AI Agent that can interact with a broad array of...NASA ToolkitThis notebook shows how to use agents to\n",
      "\n",
      "notebook will explain how to get results using Mojeek S...MultiOn ToolkitMultiON has built an AI Agent that can interact with a broad array of...NASA ToolkitThis notebook shows how to use agents to interact with the NASA toolk...Naver SearchThe Naver Search Tool provides a simple interface to search Naver and...Nuclia UnderstandingNuclia automatically indexes your unstructured data from any internal...NVIDIA Riva: ASR and TTSNVIDIA RivaOffice365 ToolkitMicrosoft 365 is a product family of productivity software, collabora...OpenAPI ToolkitWe can construct agents to consume arbitrary APIs, here APIs conforma...Natural Language API ToolkitsNatural Language API Toolkits (NLAToolkits) permit LangChain Agents t...OpenGradientThis notebook shows how to build tools using the OpenGradient toolkit...OpenWeatherMapThis notebook goes over how to use the OpenWeatherMap component to fe...Oracle AI Vector Search: Generate SummaryOracle AI Vector Search is designed for Artificial Intelligence (AI)\n",
      "\n",
      "notebook goes over how to use the OpenWeatherMap component to fe...Oracle AI Vector Search: Generate SummaryOracle AI Vector Search is designed for Artificial Intelligence (AI) ...OxylabsOxylabs is a market-leading web intelligence collection platform, dri...Pandas DataframeThis notebook shows how to use agents to interact with a Pandas DataF...Passio NutritionAITo best understand how NutritionAI can give your agents super food-nu...PaymanAIPaymanAI provides functionality to send and receive payments (fiat an...PermitPermit is an access control platform that provides fine-grained, real...PlayWright Browser ToolkitPlaywright is an open-source automation tool developed by Microsoft t...Polygon IO Toolkit and ToolsThis notebook shows how to use agents to interact with the Polygon IO...PowerBI ToolkitThis notebook showcases an agent interacting with a Power BI Dataset....PrologLangChain tools that use Prolog rules to generate answers.PubMedPubMed® comprises more than 35 million citations\n",
      "\n",
      "GradientGreenNodeGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGGreenNodeIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'learn gen ai in details'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Generation Alpha\n",
      "Summary: Generation Alpha (often shortened to Gen Alpha) is the demographic c\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langchain-tools` with `{'query': 'learn about gen ai details'}`\n",
      "responded: It seems like the Wikipedia tool call didn't quite yield the result we were looking for. Let's try again with a more specific query. \n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mWebhooks.InfobipThis notebook that shows how to use Infobip API wrapper to send SMS m...Ionic Shopping ToolIonic is a plug and play ecommerce marketplace for AI Assistants. By ...JenkinsTools for interacting with Jenkins.Jina SearchThis notebook provides a quick overview for getting started with Jina...Jira ToolkitThis notebook goes over how to use the Jira toolkit.JSON ToolkitThis notebook showcases an agent interacting with large JSON/dict obj...Lemon AgentLemon Agent helps you build powerful AI assistants in minutes and aut...LinkupSearchToolLinkup provides an API to connect LLMs to the web and the Linkup Prem...MemgraphThis will help you get started with the Memgraph toolkit.MemorizeFine-tuning LLM itself to memorize information using unsupervised lea...Mojeek SearchThe following notebook will explain how to get results using Mojeek S...MultiOn ToolkitMultiON has built an AI Agent that can interact with a broad array of...NASA ToolkitThis notebook shows how to use agents to\n",
      "\n",
      "notebook will explain how to get results using Mojeek S...MultiOn ToolkitMultiON has built an AI Agent that can interact with a broad array of...NASA ToolkitThis notebook shows how to use agents to interact with the NASA toolk...Naver SearchThe Naver Search Tool provides a simple interface to search Naver and...Nuclia UnderstandingNuclia automatically indexes your unstructured data from any internal...NVIDIA Riva: ASR and TTSNVIDIA RivaOffice365 ToolkitMicrosoft 365 is a product family of productivity software, collabora...OpenAPI ToolkitWe can construct agents to consume arbitrary APIs, here APIs conforma...Natural Language API ToolkitsNatural Language API Toolkits (NLAToolkits) permit LangChain Agents t...OpenGradientThis notebook shows how to build tools using the OpenGradient toolkit...OpenWeatherMapThis notebook goes over how to use the OpenWeatherMap component to fe...Oracle AI Vector Search: Generate SummaryOracle AI Vector Search is designed for Artificial Intelligence (AI)\n",
      "\n",
      "with Spark SQL. Sim...SQLDatabase ToolkitThis will help you get started with the SQL Database toolkit. For det...StackExchangeStack Exchange is a network of question-and-answer (Q&A) websites on ...Steam ToolkitSteam (Wikipedia)) is a video game digital distribution service and s...StripeThis notebook provides a quick overview for getting started with Stri...TableauThis notebook provides a quick overview for getting started with Tabl...TaigaThis notebook provides a quick overview for getting started with Taig...Tavily ExtractTavily is a search engine built specifically for AI agents (LLMs), de...Tavily SearchTavily's Search API is a search engine built specifically for AI agen...TiloresThis notebook covers how to get started with the Tilores tools.MCP Toolbox for DatabasesIntegrate your databases with LangChain agents using MCP Toolbox.TwilioThis notebook goes over how to use the Twilio API wrapper to send a m...UpstageThis notebook covers how to get started with Upstage groundedness\n",
      "\n",
      "notebook goes over how to use the OpenWeatherMap component to fe...Oracle AI Vector Search: Generate SummaryOracle AI Vector Search is designed for Artificial Intelligence (AI) ...OxylabsOxylabs is a market-leading web intelligence collection platform, dri...Pandas DataframeThis notebook shows how to use agents to interact with a Pandas DataF...Passio NutritionAITo best understand how NutritionAI can give your agents super food-nu...PaymanAIPaymanAI provides functionality to send and receive payments (fiat an...PermitPermit is an access control platform that provides fine-grained, real...PlayWright Browser ToolkitPlaywright is an open-source automation tool developed by Microsoft t...Polygon IO Toolkit and ToolsThis notebook shows how to use agents to interact with the Polygon IO...PowerBI ToolkitThis notebook showcases an agent interacting with a Power BI Dataset....PrologLangChain tools that use Prolog rules to generate answers.PubMedPubMed® comprises more than 35 million citations\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\LC-basics[1]\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'gen ai details'}`\n",
      "responded: It seems like you're looking for information on how to learn about Gen AI in detail. Based on the output from the previous tool calls, I'll try to provide a more specific response.\n",
      "\n",
      "Since you're interested in learning about Gen AI, I'll suggest a more relevant tool call. Here it is:\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2025-03-12\n",
      "Title: Generative AI Policies under the Microscope: How CS Conferences Are Nav\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like the tool call yielded a relevant result. Since the result is a research paper related to generative AI, I'll respond directly without using a tool. \n",
      "\n",
      "The paper appears to discuss the policies of generative AI in the context of computer science conferences. It's likely that the paper explores the implications of generative AI on the field of computer science and how conferences are navigating these changes.\n",
      "\n",
      "If you're interested in learning more about generative AI, I can provide a brief overview. Generative AI refers to a type of artificial intelligence that can generate new, original content, such as text, images, or music. This technology has the potential to revolutionize various industries, from entertainment to healthcare.\n",
      "\n",
      "Would you like me to explain more about generative AI or is there something specific you'd like to know?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how am i learn gen ai in details',\n",
       " 'output': \"It seems like the tool call yielded a relevant result. Since the result is a research paper related to generative AI, I'll respond directly without using a tool. \\n\\nThe paper appears to discuss the policies of generative AI in the context of computer science conferences. It's likely that the paper explores the implications of generative AI on the field of computer science and how conferences are navigating these changes.\\n\\nIf you're interested in learning more about generative AI, I can provide a brief overview. Generative AI refers to a type of artificial intelligence that can generate new, original content, such as text, images, or music. This technology has the potential to revolutionize various industries, from entertainment to healthcare.\\n\\nWould you like me to explain more about generative AI or is there something specific you'd like to know?\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exicuter.invoke({\"input\":\"how am i learn gen ai in details\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befcb908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59ffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
